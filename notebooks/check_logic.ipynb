{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from utils import open_pickle\n",
    "\n",
    "from cube3_game import Cube3Game\n",
    "from models import Pilgrim\n",
    "# from datasets import get_torch_scrambles\n",
    "# from utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ True, False])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "])\n",
    "\n",
    "t = torch.tensor([1, 1])\n",
    "\n",
    "print(T.shape, t.shape)\n",
    "\n",
    "eq_res = torch.eq(T, t.unsqueeze(dim=1).expand(2, 3))\n",
    "eq_res.any(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash: tensor([[ 7],\n",
      "        [16]])\n",
      "hash: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "hash_vec = torch.tensor([1, 0, 2], dtype=torch.int64)\n",
    "\n",
    "states = torch.tensor([\n",
    "    [[1, 2, 3]],\n",
    "    [[4, 5, 6]]\n",
    "], dtype=torch.int64) # (N=2, n=1, STATE_SIZE=3)\n",
    "\n",
    "exp_hash_vec = hash_vec.unsqueeze(\n",
    "    dim=0\n",
    ").unsqueeze(\n",
    "    dim=0\n",
    ").expand(\n",
    "    2,\n",
    "    1,\n",
    "    3\n",
    ")\n",
    "\n",
    "# print(\"stases:\", states.shape)\n",
    "\n",
    "hashes = torch.mul(\n",
    "    states, \n",
    "    exp_hash_vec\n",
    ").sum(dim=2)\n",
    "\n",
    "print(\"hash:\", hashes)\n",
    "print(\"hash:\", hashes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::int_repr' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m torch\u001b[38;5;241m.\u001b[39mmatmul(\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, B\u001b[38;5;241m.\u001b[39mint_repr())\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::int_repr' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1, 2], [2, 4]], dtype=torch.int64, device=\"mps\")\n",
    "B = torch.tensor([[1, 2], [2, 4]], dtype=torch.int64, device=\"mps\")\n",
    "\n",
    "torch.matmul(A.int_repr(), B.int_repr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 20], device='mps:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.mul(A, B).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "deepcube_test = open_pickle(\"../assets/data/deepcubea/data_0.pkl\")\n",
    "game = Cube3Game(\"../assets/envs/qtm_cube3.pickle\")\n",
    "generators = torch.tensor(game.actions, dtype=torch.int64)\n",
    "\n",
    "# i = 0\n",
    "# state = torch.tensor(deepcube_test['states'][i], dtype=torch.int64).unsqueeze(0)\n",
    "# solution = deepcube_test['solutions'][i]    \n",
    "\n",
    "states, actions, values = get_torch_scrambles(\n",
    "    n = 1,\n",
    "    space_size = game.space_size,\n",
    "    action_size = game.action_size,\n",
    "    length = 6,\n",
    "    permutations = generators\n",
    ")\n",
    "state = states[-1, :]\n",
    "value = values[-1].item()\n",
    "# actions = actions[-1, :]\n",
    "\n",
    "state = state.unsqueeze(dim=0)\n",
    "\n",
    "model = Pilgrim(\n",
    "    hidden_dim1 = 500, \n",
    "    hidden_dim2  = 300, \n",
    "    num_residual_blocks = 3\n",
    ")\n",
    "model.load_state_dict(torch.load(\"../assets/models/Cube3ResnetModel_policy.pt\"))\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v tensor(6.)\n",
      "actions: tensor([8, 3, 5, 0, 7, 3])\n",
      "a: 3=R -> 9=R'\n",
      "a: 7=D' -> 1=D\n",
      "a: 0=U -> 6=U'\n",
      "a: 5=F -> 11=F'\n",
      "a: 3=R -> 9=R'\n",
      "a: 8=L' -> 2=L\n",
      "\n",
      "a: 8 tensor(False)\n",
      "a: 3 tensor(False)\n",
      "a: 5 tensor(False)\n",
      "a: 0 tensor(False)\n",
      "a: 7 tensor(False)\n",
      "a: 3 tensor(True)\n",
      " \n",
      "s: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]) ; is_equal to goal?: tensor(True)\n",
      "g: tensor([24, 21, 18, 52,  4, 46, 35, 50, 29, 33, 30, 27, 43, 13, 37, 26,  7, 20,\n",
      "        15, 23,  9, 16, 22, 10, 17, 14, 11,  2, 39,  8, 32, 31,  3,  0, 41,  6,\n",
      "        47,  5, 53, 19, 40, 25, 36,  1, 42, 51, 48, 45, 34, 49, 28, 44, 12, 38]) ; is_equal to state?:  tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# i = 2\n",
    "# state = states[i, :]\n",
    "# value = values[i]\n",
    "# action = actions[:i+1]\n",
    "\n",
    "state = states[-1, :]\n",
    "value = values[-1]\n",
    "action = actions#[:i+1]\n",
    "\n",
    "print(\"v\", value)\n",
    "print(\"actions:\", action)\n",
    "s = state.clone()\n",
    "g = torch.arange(0, 54, dtype=torch.int64)\n",
    "\n",
    "for a in action.tolist()[::-1]:\n",
    "    ra = game.reverse_action(a)\n",
    "    print(f\"a: {a}={game.names[a]} -> {ra}={game.names[ra]}\")  \n",
    "    s = s[generators[ra]]\n",
    "\n",
    "s_is_g = (s == g).all()\n",
    "print(\"\")\n",
    "\n",
    "for a in action.tolist():\n",
    "    # ra = game.reverse_action(a)\n",
    "    # print(f\"a: {a}={game.names[a]} -> {ra}={game.names[ra]}\")  \n",
    "    g = g[generators[a]]\n",
    "    print(f\"a: {a}\", (g == state).all())    \n",
    "\n",
    "print(\" \")\n",
    "print(\"s:\", s, \"; is_equal to goal?:\", s_is_g)\n",
    "print(\"g:\", g, \"; is_equal to state?: \", (g == state).all())\n",
    "# print(\"states:\", state[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_actions(actions: torch.Tensor, n_gens: int):\n",
    "    n_gens_half = n_gens / 2\n",
    "    return actions - n_gens_half * (2 * (action >= n_gens_half).int() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12])\n",
      "tensor([[-0.7971, -1.1115,  1.6928,  3.3070, -1.1702, -1.1954, -1.3794, -0.6181,\n",
      "          0.0955, -0.5255, -1.2056, -1.0717]])\n",
      "tensor([[0.0121, 0.0088, 0.1459, 0.7329, 0.0083, 0.0081, 0.0068, 0.0145, 0.0295,\n",
      "         0.0159, 0.0080, 0.0092]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    _, policy = model(state)\n",
    "    policy_softmax = torch.softmax(policy, dim=1)\n",
    "\n",
    "print(policy.shape)\n",
    "print(policy)\n",
    "print(policy_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 3, 5, 0, 7, 3])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([45, 46, 47,  3,  4,  5,  6,  7,  8, 44, 43, 42, 12, 13, 14, 15, 16, 17,\n",
       "        20, 23, 26, 19, 22, 25, 18, 21, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41,  2,  1,  0,  9, 10, 11, 48, 49, 50, 51, 52, 53])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 ) =  tensor(False)\n",
      "i: 1 ) =  tensor(False)\n",
      "i: 2 ) =  tensor(False)\n",
      "i: 3 ) =  tensor(False)\n",
      "i: 4 ) =  tensor(False)\n",
      "i: 5 ) =  tensor(False)\n",
      "i: 6 ) =  tensor(False)\n",
      "i: 7 ) =  tensor(False)\n",
      "i: 8 ) =  tensor(True)\n",
      "i: 9 ) =  tensor(False)\n",
      "i: 10 ) =  tensor(False)\n",
      "i: 11 ) =  tensor(False)\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    g = torch.arange(0, 54, dtype=torch.int64)\n",
    "    print(\"i:\", i, \") = \", (g[generators[i]] == states[0, :]).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
