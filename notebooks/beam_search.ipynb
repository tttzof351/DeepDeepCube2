{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import torch\n",
    "from models import Pilgrim \n",
    "from utils import open_pickle\n",
    "from cube3_game import Cube3Game\n",
    "from datasets import get_torch_scrambles\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Cube3Game(\"../assets/envs/qtm_cube3.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generators = torch.tensor(game.actions, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = torch.tensor(\n",
    "    game.actions, \n",
    "    dtype=torch.int64,\n",
    "    device=\"cpu\",            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pilgrim(\n",
       "  (input_layer): Linear(in_features=324, out_features=400, bias=True)\n",
       "  (hidden_layer): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (residual_blocks): ModuleList(\n",
       "    (0-1): 2 x ResidualBlock(\n",
       "      (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
       "      (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
       "      (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=200, out_features=1, bias=True)\n",
       "  (output_probs_layer): Linear(in_features=200, out_features=12, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pilgrim()\n",
    "model.load_state_dict(torch.load(\"../assets/models/Cube3ResnetModel.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = open_pickle(\"../assets/data/validation/val.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values: tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "        15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,  1.,  2.,\n",
      "         3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16.,\n",
      "        17., 18., 19., 20., 21., 22., 23., 24., 25., 26.])\n",
      "predict: tensor([ 1.4058,  2.8751,  3.9373,  4.9909,  3.9373,  5.7543,  7.5723, 10.5223,\n",
      "        11.8231, 16.7446, 17.1952, 17.6661, 18.4018, 18.7154, 18.2653, 17.7984,\n",
      "        17.4907, 18.5518, 18.5048, 17.8386, 18.0384, 16.9139, 16.7532, 17.6934,\n",
      "        17.9158, 18.4731,  1.4058,  2.5966,  3.5465,  4.8532,  6.4005,  7.5903,\n",
      "         7.7779,  9.7212, 10.6549,  9.9496, 13.4054, 16.7819, 16.9136, 13.7297,\n",
      "        14.6201, 18.5912, 17.8902, 18.3051, 17.7731, 18.3851, 16.9488, 17.4943,\n",
      "        17.6450, 16.4988, 18.1087, 18.8623])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7055116"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states, actions, values = get_torch_scrambles(\n",
    "    n = 2,\n",
    "    space_size = game.space_size,\n",
    "    action_size = game.action_size,\n",
    "    length = 26,\n",
    "    permutations = permutations\n",
    ")\n",
    "# print(states[:2, :])\n",
    "\n",
    "print(\"values:\", values)\n",
    "with torch.no_grad():\n",
    "    predict_value, _ = model(states)\n",
    "    print(\"predict:\", predict_value.squeeze(1))\n",
    "\n",
    "root_mean_squared_error(\n",
    "    values.detach().cpu().numpy(),\n",
    "    predict_value.squeeze(1).detach().cpu().numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 2\n",
    "# # state = torch.tensor(validation['states'][k], dtype=torch.int64).unsqueeze(0)\n",
    "# # true_value = validation[\"values\"][k]\n",
    "# # print(state.shape, \"; true_value:\", true_value)\n",
    "# predict_value, _ = model(state)\n",
    "# print(\"predict:\", predict_value)\n",
    "# # V0 = torch.arange(0, 54)#.repeat_interleave(54//6)\n",
    "\n",
    "# # def get_neighbors(states: torch.Tensor) -> torch.Tensor:\n",
    "# #     n_gens = 12\n",
    "# #     state_size = 54\n",
    "    \n",
    "# #     return torch.gather(\n",
    "# #         states.unsqueeze(1).expand(states.size(0), n_gens, state_size), \n",
    "# #         2, \n",
    "# #         generators.unsqueeze(0).expand(states.size(0), n_gens, state_size)\n",
    "# #     )\n",
    "\n",
    "# # def search(\n",
    "# #     state, \n",
    "# #     B: int = 10000\n",
    "# # ):\n",
    "# #     neighbors = get_neighbors(state).flatten(end_dim=1)\n",
    "# #     values, _ = model(neighbors)\n",
    "\n",
    "# #     print(\"neighbors:\", neighbors.shape)\n",
    "# #     print(\"values:\", values)\n",
    "# #     pass\n",
    "\n",
    "# # search(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class BeamSearch:\n",
    "    def __init__(self, model: torch.nn.Module, state: torch.Tensor, num_steps: int, generators: torch.Tensor, device: torch.device) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the BeamSearch class.\n",
    "\n",
    "        :param model: Model to use for predictions.\n",
    "        :param state: Initial state tensor.\n",
    "        :param num_steps: Number of steps to perform in the search.\n",
    "        :param generators: Generators to create new states.\n",
    "        :param device: Device to perform computations (e.g., 'cuda', 'cpu').\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.state = state\n",
    "        self.num_steps = num_steps\n",
    "        self.generators = generators\n",
    "        self.n_gens = generators.size(0)\n",
    "        self.state_size = generators.size(1)\n",
    "        self.device = device\n",
    "        self.hash_vec = torch.randint(0, 1_000_000_000_000, (self.state_size,))\n",
    "        self.target_val = None\n",
    "\n",
    "    def get_unique_states(self, states: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Get unique states by hashing.\n",
    "\n",
    "        :param states: Tensor of states.\n",
    "        :return: Tensor of unique states.\n",
    "        \"\"\"\n",
    "        hashed = torch.sum(self.hash_vec * states, dim=1)\n",
    "        hashed_sorted, idx = torch.sort(hashed)\n",
    "        mask = torch.cat((torch.tensor([True]), hashed_sorted[1:] - hashed_sorted[:-1] > 0))\n",
    "        return states[idx][mask]\n",
    "\n",
    "    def get_neighbors(self, states: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Get neighboring states.\n",
    "\n",
    "        :param states: Tensor of states.\n",
    "        :return: Tensor of neighboring states.\n",
    "        \"\"\"\n",
    "        return torch.gather(\n",
    "            states.unsqueeze(1).expand(states.size(0), self.n_gens, self.state_size), \n",
    "            2, \n",
    "            self.generators.unsqueeze(0).expand(states.size(0), self.n_gens, self.state_size))\n",
    "\n",
    "    def states_to_input(self, states: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convert states to input tensor.\n",
    "\n",
    "        :param states: Tensor of states.\n",
    "        :return: Input tensor for the model.\n",
    "        \"\"\"\n",
    "        return torch.nn.functional.one_hot(states, num_classes=6).view(-1, self.state_size * 6).to(torch.float)\n",
    "\n",
    "    def batch_predict(self, model: torch.nn.Module, data: torch.Tensor, device: torch.device, batch_size: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform batch prediction.\n",
    "\n",
    "        :param model: Model to use for predictions.\n",
    "        :param data: Input data tensor.\n",
    "        :param device: Device to perform computations (e.g., 'cuda', 'cpu').\n",
    "        :param batch_size: Batch size for predictions.\n",
    "        :return: Predictions tensor.\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "\n",
    "        n_samples = data.shape[0]\n",
    "        outputs = []\n",
    "\n",
    "        for start in range(0, n_samples, batch_size):\n",
    "            end = start + batch_size\n",
    "            batch = data[start:end].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_output, _  = model(batch)\n",
    "                batch_output = batch_output.flatten()\n",
    "\n",
    "            outputs.append(batch_output)\n",
    "\n",
    "        final_output = torch.cat(outputs, dim=0)\n",
    "        return final_output\n",
    "\n",
    "    def predict_values(self, states: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict values for given states.\n",
    "\n",
    "        :param states: Tensor of states.\n",
    "        :return: Predicted values tensor.\n",
    "        \"\"\"\n",
    "        return self.batch_predict(self.model, states, self.device, 4096).cpu()\n",
    "\n",
    "    def predict_clipped_values(self, states: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict clipped values for given states.\n",
    "\n",
    "        :param states: Tensor of states.\n",
    "        :return: Clipped predicted values tensor.\n",
    "        \"\"\"\n",
    "        return torch.clip(self.predict_values(states) - self.target_val, 0, torch.inf)\n",
    "\n",
    "    def do_greedy_step(self, states: torch.Tensor, B: int = 1000) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform a greedy step in the search.\n",
    "\n",
    "        :param states: Tensor of current states.\n",
    "        :param B: Beam size.\n",
    "        :return: Tensor of new states after the greedy step.\n",
    "        \"\"\"\n",
    "        neighbors = self.get_neighbors(states).flatten(end_dim=1)\n",
    "        neighbors = self.get_unique_states(neighbors)\n",
    "        y_pred = self.predict_clipped_values(neighbors)\n",
    "        idx = torch.argsort(y_pred)[:B]\n",
    "        return neighbors[idx]\n",
    "\n",
    "    def search(\n",
    "            self, \n",
    "            # V0: torch.Tensor = torch.arange(6, dtype=torch.int64).repeat_interleave(54//6), \n",
    "            V0: torch.Tensor = torch.arange(0, 54, dtype=torch.int64),\n",
    "            B: int = 1000\n",
    "        ) -> int:\n",
    "        \"\"\"\n",
    "        Perform the beam search.\n",
    "\n",
    "        :param V0: Target state tensor.\n",
    "        :param B: Beam size.\n",
    "        :return: Number of steps to reach the target state, or -1 if not found.\n",
    "        \"\"\"\n",
    "        self.target_val = self.predict_values(V0.unsqueeze(0)).item()\n",
    "        states = self.state.clone()\n",
    "        for j in range(self.num_steps):\n",
    "            states = self.do_greedy_step(states, B)\n",
    "            if (states == V0).all(dim=1).any():\n",
    "                return j\n",
    "        return -1\n",
    "    \n",
    "beam_search = BeamSearch(\n",
    "    model, \n",
    "    states[20, :].unsqueeze(0), \n",
    "    100, \n",
    "    generators, \n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "beam_search.search(B=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
